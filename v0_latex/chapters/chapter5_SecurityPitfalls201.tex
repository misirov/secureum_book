\chapter{Security Pitfalls \& Best Practices 201}

\section{ERC20 Transfer}
This pitfall is specifically related to the \verb|transfer| and \verb|transferFrom| functions that allow transferring of \verb|ERC20| tokens between addresses. According to the specification, these should return \verb|bool| values, however not all token contracts adhere to the specification, so they may not return \verb|bool| values: they may not return any value at all or they may return a different value of a different type. In such cases, callers that assume the \verb|bool| values to be returned may fail, so the best practice here is for \verb|ERC20| token contracts to make sure that they are returning \verb|booln| values and for call sites to not make such assumptions: preferably sing \verb|safeERC20| wrappers from \verb|OpenZeppelin| that handle all the possible scenarios where \verb|bool|s, non-booleans or no values are being returned (and the contract simply revoked).

\section{ERC20 Optional}
The \verb|ERC20| specification makes it optional for token contracts to implement \verb|name|, \verb|symbol| and \verb|decimals| primitives. As a result, any contract that is interacting with \verb|ERC20| contracts should make sure that these primitives are indeed present and implemented by those contracts. If they want to use them, the best practice is not to make an assumption that these perimeters will always be implemented by the \verb|ERC20| contract because they are optional.

\section{ERC20 Decimals}
\verb|ERC20| contracts have a notion of decimals which typically are 18 digits in precision, and therefore the token standard specifies using an \verb|uint8| type to represent decimals, because that is sufficient to represent a value of 18. However, token contracts that do not adhere to the standard sometimes incorrectly use a \verb|uint256| type for decimals. The best practice here is to check which type is being used by the \verb|ERC20| contract and, if it is a \verb|uint256| type, then have a further check to make sure that the decimal value is less than or equal to 255, because that is the maximum value that can fit within a \verb|uint256| and a as required by the token standard.

\section{ERC20 approve()}
We have talked about the Race-condition risk from the \verb|approve| function of \verb|ERC20|. To summarize it again let's take a look at the same example that we discussed: we have a token Owner who has given an allowance of 100 tokens (\verb|approve(100)|)to a spender, then wants to later decrease that allowance to 50 tokens (\verb|approve(50)|). The spender may be able to observe this decrease operation and before that happens, it can frontrun in order to first spend the 100 tokens for which they already had the allowance from earlier. Then once \verb|approve(50)| operation succeeds, they further spend those 50 tokens as well.\\

So effectively they have ended up spending 150 tokens while the Owner intended for them to only be able to spend 50 tokens. This is possible because of frontrunning (because of the Race-condition opportunity). The best practice here is to not use the \verb|approve()| function, but instead use the \verb|increaseAllowance()| or \verb|decreaseAllowance()| functions that do not have this risk.

\section{ERC777 Hooks}
We have discussed the \verb|ERC777| token standard which aims to improve some of what are considered as shortcomings of the \verb|ERC20| standard and one of these improvements is the concept of hooks. These hooks get called before \verb|send|, \verb|transfer|, \verb|mint|, \verb|burn| and some other operations in these tokens. While they may enable a lot of interesting use cases, special care should be taken to make sure that these hooks do not make any external calls because such calls can result in reentrancy vulnerabilities. The best practice with \verb|ERC777| tokens is to check for their hooks and make sure that external calls are not being made.

\section{Token Deflation}
There's a concept of token deflation that may happen in \verb|ERC20| Token contracts. Some of these token contracts may take a fee when tokens are being transferred from one address to another. Because of this fee, the number of tokens across all the user addresses will reduce over time when they are transferred between those, so the number of tokens received by the target address may not be the same as the number of tokens sent by the sender. This depends on the amount of fee and if the fee is being charged at all.\\

The best practices here with respect to token deflation is for token contracts to generally avoid the notion of a fee that causes deflation because that could break assumptions with the contracts that interact with this token contract. For smart contract applications that work with \verb|ERC20| contracts, they should be aware if those \verb|ERC20| contracts have this notion of deflation or not, and if so, make sure that their accounting logic takes care of this deflation. This is more of a concern in smart contact applications that allow their users to interact with them using arbitrary \verb|ERC20| token contracts, and in such cases consider a guarded launch approach where the initial set of \verb|ERC20| tokens that can be used with this contract does not have this notion of deflation.

\section{Token Inflation}
\verb|ERC20| contracts could also have the opposite effect: token inflation. In this case, contracts generate interest for their token holders. This interest is distributed to holders while they make transfers. This effectively increases the number of tokens that are held by the user addresses over time, effectively meaning that when a token transfer happens, the recipient may receive more tokens than the amount originally sent that (reflecting the interest being distributed).\\

If the smart contract application is not aware of the \verb|ERC20| contract generating interest, then those interest tokens may end up getting trapped in the \verb|ERC20| contract without being realized. The best practice is again to avoid this notion of interest that causes inflation because their interacting contracts may make an assumption that no such thing is happening that could break a lot of the critical assumptions leading to vulnerabilities, or again such smart contact applications could consider a guarded launch approach where the \verb|ERC20| tokens that they work with are known not to have this notion of interest and inflation.

\section{Token Complexity}
High token complexity is considered as a security risk. We have long known that complexity in general is very detrimental to security. The same aspect holds good for \verb|ERC20| token contracts. These contracts should have a well-defined specification, they should be implementing a very simple contract because any unnecessary complexity could result in bugs: developers could make errors while developing these complex features. It is also much harder to reason about these complex features and definitely harder to find and fix bugs in such features, so the best practice is at a high level to avoid any unnecessary complexity when it comes to implementing token contracts.

\section{Token Functions}
In computer science, there is a notion of "\textit{separation of concerns}" which says that in a computer application there should be different sections, each of which addresses a very specific concern. This applies to smart contact applications that work with \verb|ERC20| token contracts as well. In this case what we mean is that a \verb|ERC20| contract should only or mostly have functions that are relevant to \verb|ERC20| tokens. They should not include any non-token related functions in them because that could introduce additional complexity, and like we just discussed complexity is detrimental to security because it could introduce bugs. At a high level one should avoid unnecessary complexity by bundling non-token related functions within a \verb|ERC20| token contract because that increases likelihood of issues in general or in the worst case security vulnerabilities.

\section{Token Address}
\verb|ERC20| contracts should be working with a single token address. What this means is that there should be a single address that maintains the balances of different users interacting with that contract, thus there is a single entry point for checking the balances of users. This is because multiple addresses within a contract can result in multiple entry points for the different balances that are held or maintained by those addresses, and not being aware of these multiple addresses and their balances can result in accounting bugs. The best practice is to make sure that an \verb|ERC20| contract works with a single address.

\section{Token Upgradeable}
We have talked about upgradability in the context of the Proxy contact pattern. This upgradability is interesting in smart contract applications where the implementation part of the Proxy can be changed to a newer version to introduce new features or to fix any bugs in the previous versions. When it comes to \verb|ERC20| token contracts, upgradability is a concern. The reason is because any change in functionality that is introduced by this upgreadeability is detrimental to the trust that the users place in these contracts. The rationale is that token functions in the contract are meant to be very simple: the \verb|mint|, \verb|burn| and \verb|transfer| functions are required to adhere to the specifications so that all the contracts or all the users interacting with this token contract are assured of the functionality implemented by these functions. The best practice here is to make sure that these token contracts are not upgradable and, if an application is interacting with token contracts to check and verify that it is not upgradable.

\section{Token Mint}
Remember that in the context of token contracts, minting refers to the act of incrementing the account balances of addresses to which those new tokens are credited, and in this context of token minting one should be aware of the contract Owner having any extra capabilities over this functionality. If this is the case, then a malicious Owner could effectively mint an arbitrary number of tokens to any address of their choice, which as you can imagine is very detrimental to the security of the token contract because all the other users using this contract and maintaining balances of these tokens in that contract will be affected because their relative share of tokens will be much smaller. The best practice here is to be aware of any such extra capabilities over this printing functionality by the contact Owner because that could be abused.

\section{Token Pause}
Remember from the previous module that the ability to pause certain contract functionality is part of what is known as a guarded launch. However, when this guarded launch approach is applied to \verb|ERC20| tokens, pausing some of their functionalities (like minting, burning or transferring) could be a concern because the authorized owners (who are allowed to pause and unpause such functionalities) or their addresses/accounts could be compromised (or they may even be malicious), resulting in pausing the contract functionality and trapping the funds of all the users interacting with that contract. The best practice here is to be aware of this risk and when interacting with token contracts to check and verify if those contracts are possible or not by certain authorized owners.

\section{Token Blacklist}
While the concept of blacklisting is commonly used in security for a long time to prevent malicious actors or actions from abusing the system this notion when applied to \verb|ERC20| contracts is of concern the reason again is because authorized users who are allowed to create and maintain this blacklist by adding actors or actions into that list or by taking them out of that list those owners could be malicious or they could be compromised and in such scenarios where a token contract has this notion of a blacklist, then because of such malicious or compromised owners the users funds could get trapped, if their addresses are blacklisted, so the best practice is again to be aware of this risk and check and verify contracts to make sure that they do not have this notion of a blacklist and, if they do be aware of what can go wrong.

\section{Token Team}
Let's now talk about the deal behind the \verb|ERC20| project and its implications on any security aspects. The team behind the \verb|ERC20| project may be publicly known (we know who the project members are, what their past projects have been and how they are connected within the community) or this team could be anonymous (the project members are only known by their handles on github, twitter, telegram or discord\dots\, and we have very little information about what they have done in the past or about their real world identities and how they are connected within the social circles of the community).\\

In the latter context, there are two schools of thought:
\begin{enumerate}
\item One school of thought thinks that an anonymous team is riskier from a security perspective of the project because we do not have a good ways to evaluate what their reputation is within the social circles, with the community based on their past projects and so on\dots\, In this case the assumption is that there's a greater risk a security risk to the project because these anonymous teams could not be as concerned about security, because any security implications or exploits might not hurt the reputation from this project, or the team members could also be imagined to have left behind bugs or back doors within the project so that later they themselves could exploit the project (what is known as "\textit{rugging}" the project. This school of thought believes that such anonymous teams should meet a higher bar when it comes to security (or security reviews on the flip side).
\item The other school of thought believes that anonymity (or pseudo-anonymity) should not matter to the security of the project. Any of your past projects based on who you are, what you have done and what your connections are within the community should not impact the security of a project. The project should be evaluated independently of who the project team members are.
\end{enumerate}

Irrespective of which school of thought you may subscribe to, this is something to be kept in mind because privacy and anonymity are strong aspirational goals of Web 3 and any such team risk could potentially translate into a legal risk for someone who may review such projects or interact with it (as users).

\section{Token Ownership}
Token ownership refers to who owns the tokens and how many tokens they own. In scenarios where there are very few users who own a lot of those tokens, then such ownership situation will allow those owners to influence the price of those tokens, the liquidity of those tokens and any potential governance actions around those tokens, because those actions will be controlled by the token ownership. This is an aspect of risk from centralization because there are very few owners holding a lot of tokens. This risk could manifest itself into a security risk as well.

\section{Token Supply}
It refers to the number of \verb|ERC20| tokens that is supported by the token contract. This supply depends on what has been implemented for that particular contract and application. It could be either low or high. The concerning situation is when a particular \verb|ERC20| contract has a very low supply of its tokens as this by implication means that the ownership may end up being concentrated within a few owners who own a significant part of the supply, in which case they have a significant influence over the price of those tokens their liquidity and therefore their volatility, so this scenario brings in an increased manipulation risk for such tokens with limited supply.

\section{Token Listing}
\verb|ERC20| tokens get listed in various places to allow trading between users. These tokens may get listed on centralized exchanges or decentralized exchanges.
\begin{itemize}
\item Decentralized exchanges are expected to be more resilient to failures and therefore are expected to be up and accessible all the time.
\item However, if token is listed on very few centralized exchanges and those exchanges happen to be inaccessible because they are down for maintenance or maybe in extreme situations where they are hacked, then a concern arises because majority of the tokens will now be inaccessible. This new low liquidity increase the price volatility of such tokens.
\end{itemize}
This is another aspect of centralization risk that one should be aware of when looking at tokens that are listed in very few exchanges.

\section{Token Balance}
Assumptions on token balances pose a security risk smart contract applications where the logic assumes that the balance of tokens that it is working with is always below a certain threshold. These applications stand the risk of those assumptions breaking if the balance exceeds those thresholds. This may be triggered by users who own a large number of tokens (typically known as whales), or it may also be triggered by what are known as flash loans.\\

A flash loan is a capability where a user is allowed to borrow a significant number of tokens without providing any collateral, but this loan has to be repaid or is forced to be repaid within the transaction itself. So by the end of the transaction, the flash loan capability makes sure that the tokens that were lent to the user are paid back to that contract, but within that context of the transaction the user has access to a significant number of tokens as provided by that flash loan contract. Such a use of large funds or flash loans may be used by users or attackers to amplify arbitrage opportunities or exploit vulnerabilities where the logic incorrectly depends on load token balances. This risk from large funds or flash loans needs to be kept in mind because it could be manipulated.

\section{Token Flash Minting}
Similar to flash loans, there is the concept of flash minting that has similar concerns. Unlike flash loans, where the total amount of tokens that can be borrowed by a user is limited by the liquidity of tokens in that particular protocol, flash minting simply mints the new tokens that are handed to the user. These again are only available within the context of a transaction because at the end of the transaction, the flash minting mechanism will destroy all the tokens that were just minted and handed to the user. Similar to flash loans, if smart contracts that are working with such \verb|ERC20| tokens make assumptions about the balances of those tokens that are available for a user, then they could lead to overflows or other serious security vulnerabilities, these again can be manipulated and there's a risk that needs to be kept aware of when dealing with external \verb|ERC20| tokens.

\section{ERC 1400 Addresses}
So far we have looked at different security aspects of \verb|ERC20| tokens let's now take a look at few other tokens that are nowhere as widely used as \verb|ERC20| tokens, but introduce some concepts that are interesting from a security perspective.\\

One of such token standards is \verb|ERC1400|. This token standard was driven by PolyMath and was related to the concept of security tokens (tokens that represent ownership in a financial security, and note that the security has nothing to do with the program or application security we are talking about). This token standard introduced the notion of permissioned addresses, which could block transfers from certain addresses. This is interesting from a security perspective because, if those addresses are malicious or if they can be compromised, then it leads to a denial of service (DoS) risk where transfers to and from such addresses can be blocked. This is a risk that we need to keep in mind if our smart contract application ever has to deal with \verb|ERC1400| tokens.

\section{ERC 1400 Transfers}
Related to the notion of permissioned addresses, \verb|ERC1400| also introduced the concept of forced transfers where there are trusted actors within the context of the standard that can perform unbounded transfers. These trusted actors can transfer arbitrary amounts of funds to whichever addresses that they choose. This introduces a transfer risk that needs to be kept in mind when dealing with such tokens.

\section{ERC 1644 Transfers}
A related token standard to \verb|ECR1400| is \verb|ERC1644| that allows the concept of forced transfers that we just discussed. This is again in the context of a controller role, which is a trusted actor in this standard that is allowed to perform arbitrary transfers of funds to arbitrary addresses. The trusted actor, if malicious or compromised, can steal funds. In this \verb|ERC| standard, there is a risk from the controller address that needs to be kept in mind.

\section{ERC 621 totalSupply}
\verb|ERC621| token standard allows a different way to control the total supply of tokens. In this standard, there is a notion of trusted actors who can change the total supply after the contract is deployed. This is allowed using the \verb|increaseSupply| and \verb|decreaseSupply| functions that are specified by the standard. This introduces what is known as a token supply risk, where the token supply of such tokens can be changed arbitrarily after the contract is deployed.

\section{ERC 884 Reissue}
\verb|ERC884| is another token standard that introduces yet another interesting security aspect. In this case, this token standard introduces the notion of cancelling and re-issuing. What this means is that the standard defines actors known as token implementers who can cancel addresses in the context of a contract that implements the standard. In that process, what these implementers do is that they move any tokens owned or held by those addresses to a new address while cancelling the older address. This, from a user's perspective, introduces token holding risk because if you are holding certain number of tokens in a particular address, then the token implementers could move those to a new address and cancel your existing address.

\section{ERC884 Whitelisting}
\verb|ERC884| also introduces the concept of whitelisting addresses, where a certain set of addresses may be whitelisted by a contract implementing the standard. Token transfers are allowed only to such whitelisted addresses and not to addresses that don't exist in this whitelist. This again, as you can imagine, is a token transfer risk because a user might want to transfer tokens to a particular address but, if that is not whitelisted, then that token transfer is not allowed 

\section{Asset Limits}
Let's now talk about a critical concept of guarded launch. This framework of ideas is widely used by almost every project in the ecosystem today in some form. It was put together and made popular by the team at Electric Capital. The fundamental idea is that when a new project is being launched, then there could be failures and vulnerabilities that have not been considered or discovered. Because of that, it makes a lot of security sense for the project to launch with minimal risk and over time increase the exposure as the project team gains more confidence in the normal functioning of the system. This idea is heavily inspired and motivated by a similar concept from the Web2 world: canary development. However in the Web3 world, because of notions of immutability, the difficulty of upgrading or updating code once it is deployed, the immediate nature, the extent of exploit possible make guarded launch in the Eeb 3 space somewhat different and perhaps difficult. It is nevertheless, more critical to implement and execute. There are multiple ways of doing guarded launches for smart contact applications. Let's take a look at the first such way of doing so.\\

The notion of asset limits: during launch the amount of assets that are managed by the smart contact application can be kept to a lower value than what is possible or desirable, and over time this asset value that is managed by the system can be increased gradually as we gain more confidence that this application does not have any further latent vulnerabilities that may get exploited and result in loss of these assets. The rationale again is that at launch time, there is likely a higher risk from latent bugs or failure modes that haven't been considered that could be exploited, so the best way to mitigate that is by introducing this notion of target launch and in this case specifically with asset limits.

\section{Asset Types}
Guarded launch can also be applied to asset types. smart contract applications can deal with multiple asset types (for example different types of \verb|ERC20| tokens) and each of these asset types may be associated with a different level of risk. for example there could be \verb|ERC20| tokens that are very widely used, well understood, time and battle tested that are generally considered as safer to use and there may also be newer or different \verb|ERC20| token types that have slightly different behavior than those that are widely understood. Those come with a much greater risk because of the lower understanding for the lower use, so from a guarded launch perspective the idea is to launch with fewer asset types that are supported initially by the application and over time increase this in a certain manner. One way to do that is to first allow the use of known assets (those generally accepted as being safe by the community), then later on as the project matures and more confidence is gained, other asset types could be allowed within this application. This again mitigates the risk in a guarded launch approach.

\section{User Limits}
Limiting the number of users that can use a newly launched application (or new versions/features of the application). This is a widely used and time tested technique in the Eeb 2 world. The same concept applies to the Web3 world where, upon guarded launch using user limits, few trusted users are whitelisted or selected (based on certain criteria) and only these users are allowed to use or interact with the application. Over time, as the project team gains more confidence that these interactions by the selected group of users is as anticipated, they can open up the application to other users as well. The the outcome with this gradual approach is similar to the other ones where there is a higher risk initially, so limit it to a few trusted users and mitigate risk in that fashion, but then the idea is to gradually increase the exposure to other sets of users as well.

\section{Usage Limits}
Similar to user limits, we can also consider a guarded launch approach where there are usage limits: upon launch the usage is limited across certain criteria, then over time these limitations are removed to allow more extensive usage. This usage could be along the aspects of transaction size, volume of the transactions daily limits that are imposed on every user or even rate limiting per user or across all the users of that application. With these two guarded launch approaches of user limits and usage limits, it's easy to imagine how risk is mitigated because if something were to go wrong, then only that limited set of users (or limited set of transactions, or the limited set of value of the tokens or any other asset held by an application) is impacted.

\section{Composability Limits}
Composability is another aspect where we can apply the guarded launch approach. Remember that composability is a defining feature of Web3 where every application can expect to interact with or to be interacted with by any other application. So in this ecosystem this makes considering these applications as LEGOs that can be picked, chosen and combined in interesting ways to build applications that were originally unexpected. While this is a defining feature and even expected by design in the Web3 ecosystem, we have also talked about the security risks from unconstrained composability. Because applications can interact with and be composed with an arbitrary number and unknown applications, their differing assumptions, configurations, requirements and expectations could lead to failure modes that have not been considered or validated in the context of the application itself. Therefore, composability becomes critical from a guarded launch perspective.\\

One way to approach it is to, again, impose limits on composability where upon launch the application is only allowed to be composed (or interact) with known applications (or protocol) and over time, extend this to arbitrary external smart contract applications that may pose an additional or increased risk. This gradual increase of exposure from whitelisted or trusted contracts extending to arbitrary untrusted contracts is another guarded launch approach.

\section{Escrow}
Another guarded launch approach is to use the familiar concept of Escrow from the traditional finance space. In this case, high value transactions (or high value operations) are escrowed where there are timelocks or specific governance capabilities that have the power to nullify or revert these transactions in case something unexpected happens with them. So the guarded launch approach is to first start off with an Escrow capability, which upon greater confidence in the system is removed.

\section{Circuit Breaker}
The next guarded launch approach is what is known as circuit breaker. This is perhaps the most widely used guarded launch approach by many of the smart contract applications that we see today. This is something that we discussed earlier where smart contracts allow certain authorized users to pause certain functions or functionalities of that smart contract when there is an emergency, and upon recovering from that emergency, there are unpause capabilities for those functionalities which again the authorized users can decide and trigger to recover from this emergency. This is something we discussed in the context of the \verb|OpenZeppelin| pausable library that allows these capabilities to be applied selectively on different functions of a smart contract. So the guarded approach is to start off with this circuit breaker pause/unpause capabilities and later renounce to these capabilities, so that those authorized users need not be trusted with pausing and unpausing which, if abused, can lead to a DoS attack on those applications.

\section{Emergency Shutdown}
An extended or extreme version of the circuit breaker capability is what is known as emergency shutdown. In scenarios where simply pausing/unpausing the smart contract application does not help us recover from the issue at hand, and where there is something fundamentally broken or wrong with the smart contract application that needs to be fixed in a more involved manner, the emergency shutdown helps authorized users to turn off the smart contact applications from allowing users to further interact with it, and it also allows users to reclaim their assets that are held by that application and, where possible, this capability could also allow one to reset and restart such smart contact applications. From a guarded launch perspective, the idea is again to launch an application with this emergency shutdown capability and over time, once we gain more confidence on the correct functioning of the system, remove this capability.\\

So far we have talked about removing these capabilities (the way that this is typically enforced within smart contracts is by removing the authorized users who can trigger those capabilities through setting the list of authorized addresses to an empty list or by setting them to Zero-addresses). this is yet another way or an extreme way to deal with the emergencies with this guarded launch approach.

\section{System Specification}
So far we have discussed security pitfalls and best practices focused on the \verb|Solidity| language, the underlying EVM, the different token standards and so on\dots\, Now we are going to level up and discuss similar pitfalls and best practices, but focusing at the application level. These are software engineering best practices that have been developed and refined over decades, that apply specifically to smart contact applications as well. These application level aspects are arguably more important to discuss from a smart contract security auditing perspective because they can't be generalized across smart contact applications like we have done with \verb|Solidity| or EVM level concepts. Because of that, there is a lack of tooling support for security pitfalls and best practices at this level, thus there is a greater dependency on manual analysis when it comes to security auditing. When that is insufficient (or incorrectly done) it has led to massive exploits that have resulted in losses of many millions of dollars.\\

With that context and motivation, let's talk about system specification. The design of any system or application starts with what is known as requirements gathering where such requirements are determined based on the target application category, the target market and the target users. Oncee those requirements are determined, they are translated (or coded) into a very detailed specification. This specification is required to describe in great detail how the different components of the system need to behave to achieve the design requirements and it's not just the "\textit{how}" aspect, but also the "\textit{why}" aspect: why is something being designed and specified the way it is being done. Without such a detailed specification, a system implementation will not have a baseline to be evaluated against the requirements that we have collected earlier. This is something critical for determining if the system behaves correctly, if the functions actually meet certain requirements that were designed (that were collected earlier). So to summarize, the design of a system begins with requirements, these requirements are translated into a very detailed specification which in future once we have an implementation allows us to evaluate, if the implementation actually meets the requirements system documentation.

\section{System Documentation}
System documentation is another critical component from a software engineering best practice. This is something that is often confused with specification. Remember that specification deals with design and requirements of the system whereas documentation deals with the actual implementation. The documentation describes what the different system components do to achieve the specification goals and how they do that. This has to cover various aspects related to the assets managed by that system, the actors within the context of that system and the various actions that these actors perform. It should also address the security specific aspects of the trust model and the threat model that are relevant to the system. So to summarize, in the design flow we start with the requirements that helps us create the specification which in turn helps us execute the implementation of that system. This implementation should be accompanied by extensive documentation that helps one evaluate it against the specification for correctness across various attributes.

\section{Function Parameters}
So with that high level view of system design let's now start discussing security aspects related to various application logic related constructs and concepts. The first one is function parameters. From a security perspective one should ensure that proper input validation has been performed for all function parameters. This is especially true if the visibility of such functions is \verb|public| or \verb|external|, because in these cases users who may potentially be untrusted can control the values that are assigned to these parameters and such tainted values can affect the control and data flow of the function and any logic thereafter. The best practice here is to make sure that there are valid sanity and threshold checks performed on these parameters, depending on what types they are. For example, if they are of the address type, then Zero-address validation should be performed because otherwise they could lead to exceptions during runtime or they could lead to tokens being burnt or access control being denied as we have discussed so far. The risk that we are trying to address here is from incorrect or invalid values being assigned to function parameters either accidentally or maliciously by users interacting with these functions.

\section{Function Arguments}
The arguments that are passed to functions, the call sites, that correspond to the function parameters are also something that need to be evaluated from a security perspective. At a high level, the arguments that are used at the call sites (the callers' arguments) should match the parameters that are required by the functions (or the callees). This matching should happen both in terms of their validity as well as their order, or in other words: the arguments at the call sites should be valid in that smart contract applications context to what the function parameters expect. The order of such arguments should match the order of the function parameters as expected. These are the best practices that need to be followed when it comes to function arguments and the corresponding function parameters.

\section{Function Visibility}
We have discussed function visibility several times. This is something that is specific to the \verb|Solidity| language that has four visibility specifiers. The order from maximum visibility to minimum visibility starts with \verb|public|, \verb|external|, \verb|internal| then finally \verb|private|. From a security perspective, to follow the principle of least privilege is critical to make sure that the strictest visibility is applied on the various functions. The reason is that, if a function is accidentally made \verb|external| or \verb|public| (when it should actually be \verb|internal| or \verb|private|) because of some critical functionality that should not be exposed to external, then this mistake can be exploited by users some of whom may be untrusted to invoke functionality that they are not supposed to have access to. This again is very relevant here because of the byzantine threat model.

\section{Function Modifiers}
Function modifiers are another interesting aspect of smart contracts written in \verb|Solidity|. They are critical from a security perspective because modifiers are used to implement access control within the smart contracts and they're also used for different types of data validation in accounting and other application specific contents. Things to be kept in mind when analyzing modifiers is: to determine if any specific modifier is missing for the functions being analyzed, to check if they have been applied incorrectly on functions that either don't require these modifiers or that require these modifiers also.\\ 
If there are multiple modifiers used on a function, we have discussed how the ordering of the modifiers affects the logic implemented. Modifiers affect both control and data flow because from a control flow perspective, they could implement authorization checks that could revert if those checks fail, and therefore affect the control flow. They could also do different types of validation of the data that is being passed to the modifiers, in which case they do affect the data flow as well. The best practice with function modifiers is to ensure that correct modifiers have been used on the correct functions and in the correct order.

\section{Function Returns}
Smart contracts typically have multiple functions defined within them, and calls to such functions execute the logic within those functions, then return control back to the call sites. In many of these cases, the functions also return a value along with the control flow. Such return values should be analyzed to make sure that the correct values are being returned. This is being done along all the paths within that function.\\

Another aspect to be checked is to ensure that for functions returning values, their call sites do indeed use those return values appropriately and do not ignore them. This is critical not only for the data flow aspect of the application logic context, but also from a security perspective. This is critical because this is the way that error conditions being returned by those function calls are caught and handled appropriately. Ignoring these could result in undefined behavior in the best cases and in the worst cases could result in serious vulnerabilities.

\section{Function Timeliness}
By timeliness we mean: when can these functions be called? Externally accessible functions (those with the \verb|external| or \verb|public| visibility) may be called at any time by users interacting with those smart contracts. On the flip side, they may never be called. The reason for this again is it could be accidental or it could be malicious, so it's not safe to assume that functions will be called in a very timely manner at specific system phases that make sense from the application logic context. Therefore, the implementation of functions within a contract should be very robust to track system state transitions, determine what state the system is currently in and in this state, which functions are expected (or make sense) to be called. For example, in the context of Proxy-based upgradable contracts where initialization functions are required to be used instead of constructors, such functions are meant to be called atomically along with contract deployment during construction to prevent anyone else from initializing those contracts with arbitrary values. Such initialization functions are not meant (or allowed) to be called after deployment.

\section{Function Repetitiveness}
Function repetitiveness is an aspect that refers to the number of times a function may be called. Again with \verb|public| or \verb|external| functions in a contract, they may be called any number of times by users. So it is not safe to assume that they will be called at all, called only once or a specific number of times as it makes sense to the application logic context. The function implementation and any state transitions happening within that function should not be making any assumptions on the number of times a particular function is called. They should be robust enough to track, prevent or ignore arbitrary repetitive invocations of functions or account for them in an idempotent way. Aagain, taking the example of Proxy-based upgradable contracts, initialization functions are meant to be called only once, which is why one of the security best practices is to use the initializer modifier from that \verb|OpenZeppelin| library that we discussed earlier.

\section{Function order}
Along with timeliness and repetitiveness, the ordering of functions also matter. This refers to which function is called and when. \verb|public|/\verb|external| functions can be triggered by users in any order, so state transitions happening within those functions should not be making any assumptions on the order in which these functions are being called just because it makes sense from that application's context. The implementation should be robust enough to handle an arbitrary order of functions being called. This may again happen accidentally by users interacting with that application or it may be triggered maliciously. Again, taking the example of Proxy-based upgradable contracts and their requirement of initialization functions: such initialization functions are meant to be called before any other contract functions can be called, that ordering is critical because initialization functions initialize state variables. Allow any other contact function, that requires those state variables to be initialized, to be called would not make sense and could lead to vulnerabilities. So function ordering is something that needs to be paid attention to from a security perspective.

\section{Function Inputs}
Function inputs determine what data functions work with in the context of those particular function calls. \verb|public| and \verb|external| functions again can be called with any arbitrary input, so it is not safe for functions to make assumptions on the validity of the arguments that are being supplied to it. Without complete and proper validation on these inputs (these could be Zero-address checks, bound checks, sanity or threshold checks depending on the type of those arguments) we can't assume that these function inputs will comply with any assumptions being made about them in the function code.

\section{Conditionals}
Conditionals are used to affect the control flow aspects of the function implementation. Functions are rarely straight line code: they have different control flow constructs such as \verb|if|, \verb|else|, \verb|for|, \verb|while|, \verb|do|, \verb|break|, \verb|continue| and \verb|return|, within the \verb|Solidity| smart contracts that are used to implement complex control flow to reflect the different conditions that these functions need to work with. Such conditionals have different predicates within them for the various checks that need to be enforced. Predicates involve the use of simple or complex expressions. These expressions involve operands or variables that are used along with operators. All these aspects of conditionals need to be checked to make sure that they enforce the control flow as anticipated by the developers. A common error is the use of the logical \verb|or| (\verb!||!) operator instead of the logical \verb|and| (\verb|&&|) operator within conditionals. These have caused serious security issues where they were being used to check for access control decisions. In such cases the authorization checks would pass, if only one of the expressions in the predicate were \verb|true| instead of requiring all of them to be \verb|true|.

\section{Access Control Spec}
Access control deals with assets, actors and actions, or in other words which actors have access to which assets and how much of those assets and what actions can the actors use to access those assets. The access control specification should detail who can access what and why should they have that access, when can that access happen and how much of those assets can the actors access. All these aspects should be very accurately specified in great detail, so that they can be correctly implemented and enforced across the different contracts and functions, and across all the system transitions and flows that happen within those contracts and functions. This should help determine the trust, the threat models and any assumptions that are being made from this model. Without such an access control specification it will be very hard or even impossible to evaluate if the implementation actually enforces all these aspects.

\section{Access Control Implementation}
The implementation of access control should make sure that every aspect of the access control that was specified in the specification is implemented uniformly and accurately across all the actors on all the assets via all the actions possible. The implementation should make sure that none of the actors, assets and flow conditions within actions are missing or may be sidestepped. Such an implementation should help us evaluate if the access control enforcement has been done correctly according to the specification.

\section{Access Control Modifiers}
Access control is typically enforced in \verb|Solidity| smart contacts by means of modifiers. Instead of implementing access control checks that are required for different functions multiple times in each of those functions, modifiers allow us to encapsulate those checks in one place and then these modifiers can be applied on any of those functions that require the access control checks implemented within them. While this encapsulation brings in the desired aspect of modularity, modifiers also impact auditability.\\

There's a school of thought that believes that modifiers are good for auditability: they make it easier because they implement all the checks in one place, so instead of reviewing the same checks multiple times in multiple functions these checks can be reviewed once within the modifier, then check if these modifiers are applied correctly to all the functions that require those checks, so that makes auditability easier.\\

On the flip side, there's another school of thought that believes that modifiers are not as good for auditability as thought. The reason is that if there is a contract that has multiple modifiers and many functions that use those modifiers, then remember that the programming style guidelines recommend modifiers to be declared and defined at the beginning of the contract, and all the functions come thereafter so, if an auditor is reviewing functions deep down within the contract and it uses multiple modifiers, then they have to scroll up to the modifiers at the beginning of the contracts to check if the desired checks were implemented and if they were implemented correctly. This switching of context in the process of scrolling is believed to not lead to good auditability.\\

Nevertheless, modifiers are used extensively and reviewing these modifiers should make sure that they are indeed present on the functions that require the checks implemented by them, that modifiers implement valid checks in a correct manner and their order is also correctly specified for functions that use multiple modifiers.

\section{Modifiers Implementation}
Given the critical role of modifiers in access control, modifiers need to be implemented correctly. But what does that mean? Access control in smart contracts is enforced on different addresses that may be classified into different roles with differing privileges. Like we discussed in earlier modules, contracts may have a simple ownership based access control or a more flexible one based on RBAC. In such RBAC scenarios we need to check that modifiers are enforcing the correct checks on the correct roles, that such checks are composed correctly. Such a correct implementation is critical to access control which is the fundamental aspect of smart contract security and therefore needs to be reviewed very carefully.

\section{Modifiers Usage}
It is not sufficient to have the modifiers implemented correctly, but they should be used or applied correctly as well: the questions of which modifiers are used, why are they used, the how/what aspects, what are the parameters passed to them and what should they do with them, the order of modifiers when more than one is present, the when aspect (under what state transitions should they be applied), finally the where aspect (the functions where they're applied to). All such aspects of modifiers their functions and any parameters should have been considered correctly.

\section{Access Control Changes}
The access control implemented may need to be changed in some scenarios. In such cases, it is critical that the change is done correctly with respect to the assets actors or actions that are impacted. Using the wrong addresses for assets or actors, or allowing the changes to happen at the wrong times in the context of the application logic may lead to loss or locking of funds. Therefore, access control changes should be validated for correctness, use a two-step process to allow recovery from mistakes and also log changes for transparency and off-chain monitoring.

\section{Comments}
Code comments can be considered as part of documentation that is in line with the code. We should ensure that the code is well commented with the correct level of details and relevant information both with NatSpec and inline comments. This will help improve readability, maintainability and also auditability because comments can help document not only the functionality, but also the rationale behind it and any assumptions made, all of which can be analyzed while manually reviewing the code.

\begin{itemize}
\item The comments should accurately reflect what the corresponding code does.
\item Discrepancies between code and comments should be addressed any to do's indicated by comments should also be addressed.
\item Commented code and stale comments should also be removed
\end{itemize}

These are all the various aspects related to comments that need to be kept in mind while developing code or manually reviewing it.

\section{Testing}
Software testing or validation is a fundamental software engineering practice that is a critical contributor to improved security. Testing validates whether the system implementation meets the requirements as detailed by the specification. Unit tests, functional tests, integration and end-to-end tests should have been performed to achieve good test coverage across the entire code base. Changes introduced with any revisions should be validated with regression tests. Smoke testing indicates at a high level if the functionality works or not. Stress testing validates extreme scenarios with borderline cases to check if those have been considered correctly. Performance and security specific testing validates those aspects respectively. Any code or parameterization used specifically for testing should be removed from production code, which in smart contracts may apply differently to testnets vs. mainnet. Leaving test parameters or configurations behind may accidentally allow their usage resulting in unexpected maintenance behavior or serious vulnerabilities, so overall we need to ensure that sufficient levels of testing have been performed across all these different categories we just mentioned.

\section{Unused}
Unused constructs may negatively impact security. This applies to any unused reports, inherited contracts, functions, parameters, variables, modifiers, events or return values; all of which should be removed or used appropriately after careful evaluation. Removing will not only reduce Gas costs, but also improve readability and maintainability of the code. Unused constructs may also be indicative of missing logic that may be a security concern, if that logic were to have implemented security related functionality, so one needs to either remove or use such unused constructs.

\section{Redundant}
Redundant constructs are also concerned. These are a kind of constructs that are not required either because there are equivalent constructs that implement the same functionality or because they are not relevant anymore. Such redundant code and comments can be confusing and should be removed or changed appropriately after careful evaluation. Similar to unused constructs, removing redundant constructs will not only reduce Gas costs but also improve readability and maintainability of the code. If redundant constructs are indicative of missing or incorrect logic, then they may be a security concern, if such logic were to have implemented security related functionality. So one needs to either remove such redundant constructs or make them relevant by adding or changing the corresponding logic.

\section{ETH}
Let's now talk about another fundamental aspect of smart contracts and Ethereum which is the way they handle Ether. Contracts that accept, manage or transfer Ether should take care of several things.
\begin{itemize}
\item They should ensure that functions handling Ether are using \verb|msg.value| appropriately, remember that \verb|msg.value| is a global variable in the context of a transaction which, for example when used or accounted multiple times (say inside loops) have led to critical vulnerabilities.
\item They should ensure that logic that depends on Ether value accounts for either less or more Ether set via \verb|payable| functions.
\item Logic that depends on contract Ether balance, accounts for the different direct or indirect ways of receiving Ether such as \verb|coinbase| transaction or \verb|selfDestruct| recipient that we have discussed earlier.
\item Logic that handles withdrawal balance and transfers does so correctly in any accounting logic.
\item Transfers should be reentrancy safe.
\item Ether can't accidentally get locked within a contract.
\end{itemize}

Functions handling Ether should also be checked extra carefully for access control input validation and error handling all these various aspects of Ether handling should be reviewed for correctness.

\section{Tokens}
Similar to Ether handling, contracts that accept manage or transfer \verb|ERC| tokens should ensure several things:
\begin{itemize}
\item They should ensure that functions handling tokens, account for different types of \verb|ERC| tokens such as \verb|ERC20|, \verb|ERC777| \verb|ERC721|, \verb|ERC1155|, etc\dots
\item They should account for any deflationary or inflationary aspects of such tokens.
\item Whether they are rebasing or not.
\item Differentiate between trusted internal tokens and untrusted external tokens.
\end{itemize}

Different tokens could come with different peculiarities in terms of their decimals of precision, their return values, reverting behavio,r support for hooks, fungibility, supporting multiple token types or deviations from specifications. All of which could again result in susceptibility to re-entrances locking or even loss of funds. Therefore, functions handling tokens should be checked extra carefully for access control input validation and error handling to ensure that these aspects are handled correctly.

\section{Actors}
The aspirational goal in Web3 is for it to be a completely permissionless system where, ideally, there are no centralized trusted actors, such as admins, responsible for any aspect of smart contracts related to either development or management. Remember that Web3 aspires to be a zero trust system where no one needs to be trusted to use and not abuse the system, because everything is and should be verified. However, in guarded launch scenarios, the goal is to start with trusted actors/assets/actions and then progressively decentralize towards automated governance by the community. For the trusted phase, all the trusted actors (their roles and capabilities) should be clearly specified in the trust and threat models, implemented accordingly and documented for user information and any evaluation. This is a critical consideration in Web3's byzantine threat model.

\section{Privileged Roles}
Let's now talk about privileged roles. Trusted actors who have privileged roles in the context of the smart contact application with capabilities to deploy contracts modify critical parameters, pause and pause the system, trigger emergency shutdown, withdraw, transfer, drain funds and allow deny other actors, should ideally be addresses controlled by multiple independent and mutually distrusting entities.\\

They should not be controlled by private keys of externally owned accounts, but we are multiSig with the high pressure, say 5-7 or 9-11 depending on the criticality of the application, the value address, and eventually they should be governed by a community or a DAO (decentralized autonomous organization) of token holders. This is because an EOA is a single point of failure, if its key is compromised or the order is malicious multiSig on the other hand brings in the security design principle of privileged separation, which is tolerant to a few of the holders being malicious or compromised.

\section{Privileged Roles pt.2}
When such privileged roles within smart contracts are being changed it is recommended not to use a single step change because it is Error-prone. For example in a single step change, if the current admin accidentally changes the new admin to a Zero-address or an incorrect address that's where the private key is not available the system is left without an operational and the contract will have to be redeployed which is not easy or even entirely feasible in some scenarios.\\

Instead one should follow a two-step approach that we have discussed earlier, the current privileged role proposes a new address for the change and in the second step the newly proposed address, then claims the privileged role in a separate transaction. This two-step change mitigates risk by allowing accidental proposals to be corrected instead of leaving the system unoperational with no or malicious privileged.

\section{Critical Parameters}
When critical parameters of systems need to be changed it is recommended to enforce the changes after a time delay that is coupled and locked with that logic. This is to allow systems users to be aware of such critical changes and give them an opportunity to exit from that system, if they do not like the upcoming changes, or adjust their engagement in any other way with the system accordingly. 

For example reducing rewards increasing fees or changing trust models in a system might not be acceptable to some users who may wish to withdraw their funds before the change and exit. Such a time locked execution of delayed change enforcement needs to be combined with event emission to notify users of upcoming changes via off-chain interfaces or monitoring tools. So the best practice is a time delay change for critical parameters that is broadcasted using events to users monitoring via off-chain interfaces the goal is to surprise less be more transparent and fair.

\section{Explicit Vs Implicit}
As a general principle everything in security is about being explicit. Instead of being implicit, implicit assumptions, implicit trust or threat models implicit acceptance of assets actors actions lead to security vulnerabilities whereas, if they are explicitly specified implemented and documented they can be reasoned about and evaluated from a security perspective.\\

Even with the \verb|Solidity| language it has progressively adopted explicit declarations of intent over the versions such as with function visibility and variable storage. So it's recommended to do the same at the application level where all requirements should be explicitly specified, so they're accurately implemented and lend themselves to validation. Implicit requirements specification and implementation assumptions should be explicitly documented and validated for correctness. Any latent implicit requirements and assumptions should be flagged as being dangerous.

\section{Configuration}
Security issues arise not only from implementation errors, but also from this configuration of system components, such as contracts, parameters, addresses and permissions all of which may lead to security issues. Such configuration aspects should be documented and validated test configurations should be clearly marked as such and separated appropriately from production configurations.\\ 

This is critical because testing is typically done with lower thresholds of different values to allow for faster or easier testing, they may also use more acceptable trust models or lower levels of thread than what is encountered in a production setting. So the best practice is to check configuration settings and make sure that they are correct relevant and validated for a production deployment.

\section{initialization}
Lack of initialization. Initializing with incorrect values or allowing untrusted actors to initialize system parameters may lead to security issues this is especially true for critical parameters, addresses, permissions and rules within the system because the default or incorrect values may be used to exploit the system. Either technically or economically. The best practice therefore to avoid security pitfalls from initialization is to check that it is done and done correctly using the right values and done, so by only the authorized users.

\section{Cleanup}
Missing the cleaning up of old state or cleaning up incorrectly or insufficiently will lead to reuse of stale state which may lead to security issues. Cleaning could be in the context of using \verb|Solidity|'s delayed primitive or even simply re-initializing variables to default values in the context of the application's logic.\\

For example this is applicable to contract state maintained in state variables within storage or even local variables within contact functions, where old scale values may lead to incorrect reads or rights in the context of the contract's logic. Cleaning up storage state using \verb|delete| primitive provides Gas refunds with an EVM some of which has changed in recent upgrades, London upgrade for example reduced Gas refunds of s stores. Nevertheless, there are benefits besides security to this aspect of cleaning up.

\section{Data Processing}
At a very high and perhaps abstract level data, processing issues may lead to security issues in the application logic's context this could arise from several reasons such as while processing critical data or from processing of painted input data.\\

Processing could be missing or incorrectly implemented this could either resolve from a faulty specification or implementation without being caught during validation therefore all aspects of data processing should be reviewed for potential security impact

\section{Data Validation}
A specific aspect of data processing that we just discussed is data validation where contract functions check, if they receive data from external users or other contracts is valid, based on aspects of variable types, lower high thresholds or any other application logic specific context.\\

Validation issues very frequently lead to security issues. Missing validation of data or incorrectly insufficiently validating data especially tainted data from untrusted users will cause untrustworthy system behavior which may lead to security issues. Sanity and threshold checks are therefore critical aspects of data validation.

\section{Numerical Issues}
Another specific type of data processing is numerical processing, where the logic operates on numerical values incorrect numerical computation will almost always cause unexpected behavior some of which may lead to serious security issues. If not accounting miscalculations these may be related to overflow/underflow, precision handling, type casting, parameter return values, decimals, ordering of operations with multiplication/division and loop indices among other things.\\

The recommended best practice is to adopt widely used libraries for special mathematical support such as Fixed-point or floating point numbers and combine this with extensive testing using fuzzing and other tools meant to specifically test constraints and invariants for numerical issues.

\section{Accounting Issues}
Another specific type of data numerical processing is that related to accounting incorrect or insufficient tracking or accounting of business logic related aspects. Such as states phases permissions, rules, deposits, withdrawals of funds, mints. births, transfers of tokens or rewards penalties, fees within d5 applications all these may lead to serious security issues. We have seen numerous vulnerabilities specifically related to this aspect.\\

Therefore accounting aspects related to application logic states or transitions or numerical aspects as outlined earlier should be carefully reviewed to make sure they are correct and complete.

\section{Access Control}
We have discussed this multiple times, but this aspect of access control, warrants revisiting again because it's central and critical to security. Incorrect or insufficient access control or authorization related to system actors rules assets and permissions, may certainly lead to security issues.\\

Therefore the notion of assets actors actions in the context of trust and threat models should be reviewed with the utmost care to avoid such security issues.

\section{Auditing \& Logging}
Recording or accessing snapshots or logs of important events, within a system is known as audit logging. The recorded events are called audit logs note that this auditing from a logging perspective is different from the concept of external reviews, which is also called auditing. Auditing and logging are important for monitoring the security of an application.\\

In the context of smart contracts this applies to event emissions, the ability to query values of public state variables, exposed getter functions, and recording appropriate error strengths from requires, asserts and rewards. Incorrect or insufficient implementation of these aspects will impact off-chain monitoring and instant response capabilities which may lead to security issues. Correct and sufficient audit and logging is therefore something that also needs to be paid attention to for reasons of monitoring detecting and recovery aspects of security.

\section{Cryptographic}
Incorrect or insufficient cryptography, especially related to on-chain signature verification, or off-chain key management, will impact access control and may lead to security issues. So, aspects of keys accounts hashes signatures and randomness need to be paid attention to along with the fundamental concepts of ECDSA signatures and \verb|keccak-256| hashes.\\

there are also other deeper and dual cryptographic aspects one will encounter in Ethereum applications or protocol upgrades with abbreviations such as \verb|BLS|, \verb|RANDAO|, and \verb|VDF| and also zero knowledge (ZK) aspects. At a high level, cryptography is fundamental and critical to security and even a tiny mistake here can be disastrous surely leading to security vulnerabilities.

\section{Error Reporting}
Incorrect or insufficient detecting reporting and handling of error conditions will cause exceptional behavior to go unnoticed which may lead to security issues. At a high level security exploits almost always focus on exceptional behavior that is normally not encountered or validated or noticed.\\

Such exceptional behavior is what is anticipated caught and reported by error conditions. Any deviations from the specification are errors that should be detected reported and handled appropriately by the implementation.

\section{DoS}
Denial of service or DoS is also a security concern. Traditionally security has been considered as a triad referred to as CIA which stands for confidentiality integrity and availability. DoS affects availability and in this case that of the smart contract application. Preventing other users from successfully accessing system services by either modifying system parameters or shared state causes denial of service issues which affects the availability of the system.\\

The effects of this could cause users to have their funds locked reduce profits prevent from having their transactions included and therefore interactions with the contracts denied. Attackers may cause DoS without any apparent or immediate economic benefits to themselves and do, so by spending Ether on the Gas or any other tokens required for such duress causing interactions, which is typically referred to as griefing. So the best practices here are to recognize and minimize any such attributes in the smart contracts or application logic that could enable dos.

\section{Timing}
Timing issues can have a security impact. Incorrect assumptions on timing of user actions which can't be controlled. Triggering of system state transitions or dependencies on blockchain state blocks transactions may all lead to security issues depending on the application logic context. Therefore any timing attributes or logic within smart contact applications should be analyzed to check for such issues.

\section{Ordering}
Similar to timing issues incorrect assumptions on ordering of user actions or system state transitions may also lead to security issues. For example a user may accidentally or maliciously call a finalization function or other contract functions even before the initialization function has been called, if the system allows this to happen.\\

Attackers can front run or back run user interactions to force assumptions or ordering to fail Front-running is when the attackers race to finish their transaction or interaction before the user. Back-running is when they raise to be behind or right after the user's transaction of interaction.\\

Combining these two aspects can also be exploited in what are known as sandwich attacks where the user's transaction or attraction is sandwiched between those from the patent. So the best practice is to pay attention to the related aspects of timing and ordering attributes and evaluate, if they can be abused in any manner.

\section{Undefined Behavior}
Undefined behavior that is triggered accidentally or maliciously may lead to security issues. But what is undefined behavior? Any behavior that is not defined in the specification, but is allowed either explicitly or inadvertently in the implementation is undefined behavior.\\

Such behavior may never be triggered in normal operations but, if they are triggered accidentally in exceptional conditions that may result in rewards. However, if such behavior can also be exploited in some manner that leads to security issues in some cases it may not be clear, if such undefined behavior is a security concern or not, but nevertheless should be treated as such. The best practice is to make sure all acceptable behavior is detailed in the specification implemented accordingly and documented thoroughly.

\section{Interactions}
External interactions can have a security impact. Such interactions could be with assets actors or actions that are outside the adopted trust and threat models and hence external. Interacting with such external components for example tokens contracts or Oracles forces the system to trust or make assumptions about their correctness or availability which requires validation of their existence before interacting with them and any outputs from such interactions\\

Therefore such external interactions can have security implications and need to be considered carefully. Increasing dependencies and composability make this a significant challenge.

\section{Trust}
Trust is a fundamental concept in security. Thus minimization (or zero trust in the extreme case) is often the aspirational goal because trusted assets actors actions may be compromised or become malicious to subvert security. Trust minimization is a foundational value upon which Web3 is being picked, and one of the key tenets of decentralization where the notions of insiders and outsiders blurred and users may misuse the system under assumptions of Byzantine threat models.\\

So incorrect or insufficient trust assumptions about or among system actors and external entities may lead to privileged escalation or misuse, which may further lead to security issues the best practice therefore is to never trust, but always verify both the principle as well as in practice.

\section{Gas}
Remember that the notion of Gas and Ethereum stems from the need to bound computation because of the Turing completeness of the underlying EVM.  Incorrect assumptions about Gas requirements especially for loops or external calls will lead to Out-of-Gas exceptions which may further lead to security issues such as failed transfers or locked funds. Gas usage must therefore be considered while reviewing smart contracts to evaluate any assumptions leading to security implications of denial of service.

\section{Dependency}
Dependencies on external actors assets actions or software such as contracts, libraries, tokens, Oracles or Relayers will lead to trust correctness and availability assumptions which, if or when broken may lead to security issues. Dependencies therefore should be well documented and evaluated for such trust assumptions and threat models.

\section{Constant}
Issues may arise, if you assume certain aspects to be constant. That is they do not change for the duration of a transaction or even the contract's lifetime, but in fact they are not constant and change for some reason. Hard-coded assumptions could manifest for example in hard-coded contract configuration parameters. Example: Block times, block Gas Limits, opcode Gas prices, addresses, roles or permissions. Any such incorrect assumptions about system actors entities or parameters being constant may lead to security issues, if and when such factors change unexpectedly.

\section{Fresh}
Freshness of an object is an aspect that indicates, if it is the latest one in some relevant timeline or, if it is stale indicating that there is an updated value or version in that corresponding timeline. Using stale values and not the most recent values leads to freshness issues that could manifest into security issues.\\

Concrete examples are the use of nonsense in transactions to prevent replay attacks by repeating older transactions or the asset prices obtained from Oracles which, if stale can cause significant accounting issues leading to price manipulations and resulting vulnerabilities. Therefore increased assumptions about the status of or data from system actors being fresh because of lack of updation or availability may lead to security issues, if and when such factors have been updated and result resultant stale values being used instantly.

\section{Scarcity}
Scarcity refers to the notion that something is available in only few numbers. This may refer to assets or actors in the context of an application where assumptions may be made that, there are only a few assets or actors interacting with the application. Incorrect assumptions about such Scarcity say for example tokens funds available to any system actor will lead to unexpected outcomes, if those assumptions are broken which may further lead to security issues.\\

For example susceptibility to flash loads or flash mints, related overflows is an example where the vulnerable contract makes a Scarcity related assumption and applies that to the size or type of variables used to maintain token balances. Which, if broken because of flash loans or mints can lead to overflows, if not mitigated appropriately. This is also related to civil attacks where an attacker subverts a system by creating a large number of identities and uses them to gain a disproportionately large influence where the system assumption on fewer unique identities is broken in some sense. Therefore one needs to evaluate if there are any Scarcity or abundance assumptions in an application that could cause security issues.

\section{Incentive}
Incentives are another fundamental aspect of blockchains and Web3. Mechanism design or crypto economics dictates almost everything in this space including infrastructure provisioning development and governance of systems. What incentives are provided and how much incentives are provided may be used or abused while interacting with smart contract applications.\\ 

Incentives could be either rewards or penalties, so for example incentives to liquidate positions in defile lending or applications of incentives to cause denial of service or briefing of a system. Incorrect assumptions about such incentives for system or external actors to either perform or not perform certain actions will lead to expected behavior not being triggered or unexpected behavior being triggered both of which may lead to security issues.

\section{Clarity}
Lack of clarity in assets actors or actions or system specification, documentation, implementation, user interface or user experience will lead to incorrect assumptions and unanticipated expectations or outcome which may lead to security issues. Therefore increasing the clarity by clearly thoroughly and accurately specifying implementing and documenting all security relevant aspects will help in mitigating risks from lack of clarity.

\section{Privacy}
Privacy and security are very closely related. In this context there could be privacy issues related to assets actors and their actions. Remember that data and transactions on the Ethereum blockchain are not private anyone can observe contract state and track transactions both included in the block, those pending in the \verb|mempool|. So incorrect assumptions about such privacy aspects of data or transactions that manifest in implementation or assumed trust and threat models can be abused leading to security issues.

\section{Cloning}
Cloning in this context refers to copy pasting code from other libraries contracts different parts of the same contract or from entirely different projects with minimal or no changes. The configurations context assumptions bugs and bug fixes for the original code may be ignored or used incorrectly in the context of the cloned code. 

This may result in incorrect code semantics for the context being copied to copy over any vulnerabilities or miss any security fixes applied to the original code all of which may lead to security issues. There have been security vulnerabilities because of cloning incorrectly some of which have led to exploits as well. Cloning therefore is risky and has serious security implications.

\section{Logic}

The last concepts we've discussed are generalizations and higher level concepts related to application logic level issues that can't be specifically codified in tools or generalized because they differ across applications. These are perhaps much harder to reason and detect because it requires deep understanding of the application logic and hence there's mostly manual effort in security reviews. Such business logic which is application specific should have been translated from requirements to the specification, then implementation with all of it validated and documented accurately especially the security relevant aspects.\\

Without that security reviewers have to infer assumptions constraints program and variants trust and threat models which is not very effective or efficient. Application logic related vulnerabilities are perhaps the hardest to detect and have resulted in serious exploits. This is therefore of utmost importance to security and hopefully the 50 + concepts that we have discussed for the majority of this module will be helpful in doing so.

\section{Principle \#1}

We will now discuss the 10 principles from Saltzer and Schroeder's secure design principles which are proposed by them in 1975 and have been widely cited and used in various aspects of information security ever since.\\

The first one is that of least privilege which states that every program and every user of the system should operate using the least set of privileges necessary to complete the job which means that we should ensure that various system actors have the least amount of privilege granted as required by their roles to execute their specific tasks. Because granting excess privilege that what is absolutely required is prone to misuse or abuse when trusted actors misbehave or their access is hijacked by malicious entities privileges. Therefore should be need-based.

\section{Principle \#2}
The second principle is about separation of privileges which states that where feasible a protection mechanism that requires two keys to unlock it is more robust and flexible than one that allows access to the presenter of only a single key.\\

This means that we should ensure critical privileges are separated across multiple actors, so that, there are no single points of failure or abuse. A good example of this is the use of a Multi-Sigs address versus an EOA for privileged actors such as contract Owner, admin or gobernement? who control key contract functionalities such as pause and pause shutdown, emergency fund, drain, upgradability of contracts, allow, deny lists and critical parameters.\\

The multisig address should be composed of entities that are different and mutually distrusting or verifying because such a privilege separation prevents single points of failure.

\section{Principle \#3}

The third principle is that of least common mechanism. Which states that we should minimize the amount of mechanism common to more than one user and depended on by all users.\\

This means that we should ensure that only the least number of security critical modules or paths as required, are shared amongst the different actors of code, so that impact from any vulnerability or compromise and shared components is limited and contained to the smallest possible subset.\\

In other words common points or parts of failure are minimized, there are pros and cons of this approach that need to be made in depending on the context.

\section{Principle \#4}
The fourth principle is that of fail-safe defaults which states that we need to base access decisions on permission rather than exclusion, so we need to ensure that variables or permissions are initialized to fail-safe default values which deny access by default, but can later be made more inclusive or permissive, if and when necessary.\\ 

Instead of opening up the system to everyone by default which may include untrusted actors. We have discussed this in the context of guarded launch for assets actors and actions. Such fail-safe initial defaults could apply to function visibility critical parameter, initializations and permissions of assets actors and actions, there are again pros and cons of this approach that need to be considered as it applies to open or closed systems given the emphasis of Web3 on aspects of openness permissionless participation and composability among other things.

\section{Principle \#5}
The fifth principle is that of complete mediation which states that every access to every object must be checked for authority. Which means that we should ensure that any required access control is enforced along all access paths to the object or function being protected. Examples are missing modifiers, permissive visibility or missing authorization flows. Complete mediation, therefore requires access control enforcement on every asset after action along all paths and at all times.

\section{Principle \#6}
The sixth principle is that of economy of mechanism, which says keep the design as simple and small as possible. Which in this context can be applied to ensure that contracts and functions are not overly complex or large, so as to reduce readability maintainability or even auditability. This embodies the keep it simple and stupid or KISS Principle in some ways because complexity typically leads to insecurity and hence should be kept as low as possible.

\section{Principle \#7}
The seventh principle is that of open design which states that the design should not be secret. This is especially relevant to the Web3 space as we have discussed earlier because smart contracts are expected to be open-sourced, verified and accessible to everyone for permissionless participation and composability. Security by obscurity of code or underlying algorithms is not an option. Security should be derived from the strength of the design and implementation under the assumption that Byzantine attackers will study their details and try to exploit them in arbitrary ways.

\section{Principle \#8}
The eighth principle is that of psychological acceptability which states that it is essential that the human interface be designed for ease of use, so that users routinely and automatically apply the protection mechanisms correctly. Which in our context means that we need to ensure that security aspects of smart contract interfaces and system designs flows are human friendly and in queue them, so that we can program them or use them with ease and with minimal risk. This is a significant challenge in the web 3 space today where, there is a lot of early and experimental software undergoing rapid changes, but something to be kept in mind from a security perspective as things evolve and systems get more mass adoption.

\section{Principle \#9}
The ninth principle is work factor, which recommends to compare the cost of circumventing the mechanism with the resources of a potential adapter. Which is very relevant and perhaps at an extreme in the case of smart contracts in Web3 because given the magnitude of value managed by smart contracts it is safe to assume that Byzantine attackers will risk the greatest amounts of the resources possible across intellectual social and financial capital to support such systems. And given the general state of current smart contracts the cost of circumventing is not very high, relative to hardened software or systems in the Web2 space for various reasons that we have discussed earlier. \\

The rewards from exploiting them are in tens or even hundreds of millions of dollars in some cases, so the risk versus reward is extremely skewed here. Therefore the mitigation mechanisms must appropriately factor in the highest levels of threat and risk.

\section{Principle \#10}

The final tenth principle is about compromise recording which states that mechanisms that reliably record that a compromise of information has occurred can be used in place of more elaborate mechanisms that completely prevent loss.\\

One way to interpret this is to say that achieving improving bug-free code is theoretically and practically impossible for real world smart contracts. Therefore one should strive for the best in performing all security due diligence and reduce the attack surface as much as possible. While in the same time, anticipate residual risk to exist in the deployed system. Anticipate that there will be potential incidents that exploit them and therefore have an instant response plan ready for that.\\

For doing that we can ensure that smart contracts and their accompanying operational infrastructure can be monitored and analyzed at all times for minimizing loss from any compromise due to vulnerabilities and exploits. As a concrete example critical operations in contracts should emit events to facilitate off-chain monitoring at runtime, where the available monitoring tools are used on smart contracts of interest to analyze not only such events, but also transactions interacting with them their Side-effects and potential security impacts.
